1.给出一个方案--将平台lite仿真测试移植到v9m项目

- v9m项目代码分支
  - x86编译通过
  - 仿真zsim代码适配（仿真器部分）
  - 测试用例接口或逻辑适配
  - 能跑通单个case流程
  - 批量用例场景设计和开发
  - 批量执行，相关问题优化
  - 仿真器稳定和测试用例
- 实车业务熟悉
  - 上车体验功能测试
  - 了解jira问题等
  - 

2.具体方案

- 软件框图
- 硬件资源
- 开发任务阶段计划（按月份之类的）
- 问题点这些是后面再去整理的，先确定方案可行

























xxxx不能照抄

v9m vave 

1.数据流框图&环境

- zros和仿真数据流框图（搞懂关系）
- 软硬件环境分布
  - 使用场景
  - 环境依赖
- 整体执行过程

2.自动化测试框架

- 测试节点
  - 节点逻辑
  - 调用接口
  - 校验点
- 自动化测试脚本
  - 用例执行（数据驱动、测试计划、html报告）
  - 场景库设计

3.工具介绍

- carla仿真工具
  - 原理
  - 使用说明
- vpcar地图场景编辑器
  - 原理
  - 使用说明
- DMS
  - 使用场景
  - 使用说明
- foxglove

4.阶段性计划

- x86编译通过
- 仿真zsim代码适配（仿真器部分）
- 测试用例接口或逻辑适配
- 能跑通单个case流程
- 批量用例场景设计和开发
- 批量执行，相关问题优化
- 仿真器稳定和测试用例
  - 传感器和摄像头等仿真实现
- 稳定性和一致性验证
- 上线测试



5.可能存在的问题点

- 编译适配
- 识别效果
- 节点帧率&挂死
- 



周二：

![image-20230815160044093](/home/user/.config/Typora/typora-user-images/image-20230815160044093.png)0.更新版本方式

1.测试节点：多线程队列 一个接受topic，一个解析写入csv

2.shell调用测试节点

3.python预处理配置文件（替换远程板子环境）、多个测试场景集（数据集导入（循环）、定时）、上传测试节点、远程连接板子，运行shell脚本，运行完成后csv复制到本地、比对校验形成报表(od同一time交并比>70%)(真值前后同一id或匹配度最高的帧值作为匹配结果)、cv中心点比对、标激光点云、标注？？？（时机）

1.

![image-20230815160932925](/home/user/.config/Typora/typora-user-images/image-20230815160932925.png)

1.环境问题 板子或pc

2.录得bag和回放的bag有啥区别吗



整体流程：



1.根据指定的数据集场景，准备zrosbag、版本、相关配置文件、shell脚本推送到执行端

2.运行shell脚本（启动回放和测试节点），执行完成后拉取csv结果文件和其他需要的文件到本地

3.根据标注真值进行结果校验对比，生成可视化图表。

1.fused_topic_2csv模块（c++）

获取回放生成的部分topic，提取信息存为csv

2.用例层：

1.pre_test:设置机器ip、数据集路径等路径

2.run_test：

- 将相关zrosbag、回放节点配置文件、测试节点推送到执行机，替换版本相关文件
- 运行shell脚本（启动相关节点进行回放、记录相关topic并存为csv、运行完成后杀死节点）
- 执行完成后拉取csv结果文件和其他需要的文件到本地
- 根据标注真值进行结果校验对比，生成可视化图表。

3.post_test:清理执行环境---





class test_obj(ip,bag_path,config_path,zros_path){}



public run_test(test_obj)

{

pre_test()

run_test()

post_test()

}



自动驾驶感知数据回放评测方案可以按照以下步骤进行：

1. 数据收集和记录：使用自动驾驶系统在真实道路环境中收集感知数据。这些数据可以包括摄像头图像、激光雷达点云、雷达数据等。同时，记录车辆的准确位置、姿态和其他相关信息。
2. 数据预处理：对收集到的感知数据进行预处理，包括数据校准、去噪、滤波和坐标转换等。确保数据的准确性和一致性。
3. 数据回放：将预处理后的感知数据按照时间顺序进行回放。根据数据的时间戳，逐帧将感知数据输入到自动驾驶系统中。
4. 评估指标定义：定义一系列评估指标来评估自动驾驶系统的感知性能。例如，目标检测的准确率、障碍物跟踪的精度、车道线检测的准确性等。
5. **感知算法评估：使用回放的感知数据对自动驾驶系统的感知算法进行评估**。比较感知结果与真实数据之间的差异，并计算评估指标的数值。
6. 结果分析和可视化：分析评估结果，识别感知算法的优势和不足之处。**使用可视化工具将感知结果与真实数据进行对比，以便更直观地理解感知性能**。
7. 改进和优化：根据评估结果，对感知算法进行改进和优化。可能需要调整参数、改进算法逻辑或增加训练数据等。

8. **重复评估**：在改进和优化后，重复执行数据回放评估方案。使用更新的感知算法和改进后的参数，再次对自动驾驶系统进行评估。比较新的评估结果与之前的结果，以验证改进的效果和性能提升。

9. **多样性测试**：除了使用单一数据集进行回放评估外，还可以考虑使用多样性的数据集来评估感知算法的鲁棒性和泛化能力。收集不同场景、不同天气条件和不同交通情况下的感知数据，并进行回放评估。

10. **定量和定性分析**：除了计算评估指标的数值，还可以进行定性分析。观察感知结果的直观表现，如目标检测的漏检和误检情况、障碍物跟踪的稳定性等。结合定量和定性分析，得出全面的感知性能评估结论。

11. **持续改进**：感知数据回放评估方案应作为一个持续改进的过程。随着自动驾驶系统的发展和算法的更新，不断进行数据回放评估，以验证改进的效果和性能提升。

通过以上的自动驾驶感知数据回放评估方案，可以对自动驾驶系统的感知算法进行全面的评估和优化，提高系统的感知性能和安全性。









自动驾驶自动泊车中进行感知数据回放评测的方案可以按照以下步骤进行：

1. 收集感知数据：在实际自动泊车场景中，使用车辆配备的感知传感器（如摄像头、激光雷达等）进行数据采集。记录车辆周围环境的感知数据，包括图像、点云等。

2. 标注感知数据：对收集到的感知数据进行标注，标注车辆、行人、障碍物等目标的位置、边界框、类别等信息。可以使用标注工具或者众包服务进行标注。

3. 构建感知数据集：将标注的感知数据整理成数据集的形式，包括图像数据和对应的标注信息。可以使用常见的数据集格式，如COCO、KITTI等。

4. 设计回放评测方案：根据自动泊车的感知算法和评测指标，设计感知数据回放评测方案。考虑以下几个方面：
- 回放策略：确定感知数据的回放策略，包括回放速度、回放顺序等。可以按照时间顺序回放，或者根据特定场景进行回放。
- 评测指标：选择适当的评测指标，如目标检测的准确率、漏检率、误检率等。根据评测指标设计评估方法和计算方式。
- 评测场景：选择不同的评测场景，包括不同的道路类型、交通情况、光照条件等。确保评测结果具有一定的泛化性和可靠性。

5. **实施感知数据回放评测**：

使用自动化脚本或工具，将设计好的感知数据回放方案应用于自动驾驶自动泊车系统。以下是实施评测的步骤：

- **加载感知数据集**：将标注好的感知数据集加载到自动泊车系统中，确保系统能够读取和处理这些数据。

- **执行感知数据回放**：按照设计好的回放策略，将感知数据按照一定的速度和顺序回放给自动泊车系统。确保回放过程与实际场景尽可能接近。

- **记录评测结果**：在回放过程中，记录自动泊车系统的感知结果。包括目标检测的结果、定位精度等评测指标。

- **计算评测指标**：根据设计好的评测指标和计算方式，对感知结果进行评估和计算。比较系统的输出与标注数据的一致性，计算准确率、漏检率、误检率等指标。

- **分析评测结果**：分析评测结果，识别系统在不同场景下的性能表现。确定系统的优势和改进空间，并与预期的性能要求进行比较。

- **迭代评估**：在改进和优化后，重复执行数据回放评估方案。使用更新的感知算法和改进后的参数，再次对自动驾驶系统进行评估。比较新的评估结果与之前的结果，以验证改进的效果和性能提升

通过以上步骤，可以对自动驾驶自动泊车系统进行感知数据回放评测。这样的评测方案可以帮助开发人员了解系统在不同场景下的感知能力，并指导系统的优化和改进。























```
1.脚本从命令行参数中获取了一些输入，包括ip、data_Path、result_Path和tags

2. 在pre_test方法中，代码执行了一些预测试的准备工作，包括将脚本文件和一些其他文件复制到指定的路径，并获取版本信息。

7. 在post_test方法中，代码执行了一些测试后的清理工作，包括删除一些文件和关闭测试报告
```

